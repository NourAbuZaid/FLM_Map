{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to_timemap\n",
    "\n",
    "> Exports a timemap-ready XLSX from some other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import json\n",
    "import xlsxwriter\n",
    "from datetime import datetime\n",
    "from fastscript import *\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "import os\n",
    "from string import Template\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "repo_dir = list(Path(os.getcwd()).parents)[1]\n",
    "targets = repo_dir/'json'/'targets_bycountry'\n",
    "countries = [Path(x) for x in targets.glob(\"**/*\") if x.is_dir()]\n",
    "output = repo_dir/'temp'\n",
    "output_xlsx = output/'datasheet-server'/'data'\n",
    "output_xlsx.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     1,
     14
    ]
   },
   "outputs": [],
   "source": [
    "#export\n",
    "DEFAULT_HEADERS = [\n",
    "    \"id\",\n",
    "    \"description\",\n",
    "    \"location\",\n",
    "    \"date\",\n",
    "    \"time\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"category\",\n",
    "    \"filter0\",\n",
    "    \"colour\"\n",
    "]\n",
    "\n",
    "COLS = [\n",
    "    \"#FFFF00\", \"#1CE6FF\", \"#FF34FF\", \"#FF4A46\", \"#008941\", \"#006FA6\", \"#A30059\",\n",
    "        \"#FFDBE5\", \"#7A4900\", \"#0000A6\", \"#63FFAC\", \"#B79762\", \"#004D43\", \"#8FB0FF\", \"#997D87\",\n",
    "        \"#5A0007\", \"#809693\", \"#FEFFE6\", \"#1B4400\", \"#4FC601\", \"#3B5DFF\", \"#4A3B53\", \"#FF2F80\",\n",
    "        \"#61615A\", \"#BA0900\", \"#6B7900\", \"#00C2A0\", \"#FFAA92\", \"#FF90C9\", \"#B903AA\", \"#D16100\",\n",
    "        \"#DDEFFF\", \"#000035\", \"#7B4F4B\", \"#A1C299\", \"#300018\", \"#0AA6D8\", \"#013349\", \"#00846F\",\n",
    "        \"#372101\", \"#FFB500\", \"#C2FFED\", \"#A079BF\", \"#CC0744\", \"#C0B9B2\", \"#C2FF99\", \"#001E09\",\n",
    "        \"#00489C\", \"#6F0062\", \"#0CBD66\", \"#EEC3FF\", \"#456D75\", \"#B77B68\", \"#7A87A1\", \"#788D66\",\n",
    "        \"#885578\", \"#FAD09F\", \"#FF8A9A\", \"#D157A0\", \"#BEC459\", \"#456648\", \"#0086ED\", \"#886F4C\",\n",
    "        \"#34362D\", \"#B4A8BD\", \"#00A6AA\", \"#452C2C\", \"#636375\", \"#A3C8C9\", \"#FF913F\", \"#938A81\",\n",
    "        \"#575329\", \"#00FECF\", \"#B05B6F\", \"#8CD0FF\", \"#3B9700\", \"#04F757\", \"#C8A1A1\", \"#1E6E00\",\n",
    "        \"#7900D7\", \"#A77500\", \"#6367A9\", \"#A05837\", \"#6B002C\", \"#772600\", \"#D790FF\", \"#9B9700\",\n",
    "        \"#549E79\", \"#FFF69F\", \"#201625\", \"#72418F\", \"#BC23FF\", \"#99ADC0\", \"#3A2465\", \"#922329\",\n",
    "        \"#5B4534\", \"#FDE8DC\", \"#404E55\", \"#0089A3\", \"#CB7E98\", \"#A4E804\", \"#324E72\", \"#6A3A4C\",\n",
    "        \"#83AB58\", \"#001C1E\", \"#D1F7CE\", \"#004B28\", \"#C8D0F6\", \"#A3A489\", \"#806C66\", \"#222800\",\n",
    "        \"#BF5650\", \"#E83000\", \"#66796D\", \"#DA007C\", \"#FF1A59\", \"#8ADBB4\", \"#1E0200\", \"#5B4E51\",\n",
    "        \"#C895C5\", \"#320033\", \"#FF6832\", \"#66E1D3\", \"#CFCDAC\", \"#D0AC94\", \"#7ED379\", \"#012C58\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     4,
     16
    ]
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def dt(d: str) -> datetime:\n",
    "    return datetime.strptime(d, '%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "def getDate(item: str) -> datetime:\n",
    "    lspt = item.get('lastSpotted')\n",
    "    if lspt is not None:\n",
    "        return dt(lspt)\n",
    "    startTime = item.get('startTime')\n",
    "    if startTime is not None:\n",
    "        return dt(startTime)\n",
    "    endTime = item.get('endTime')\n",
    "    if endTime is not None:\n",
    "        return dt(endTime)\n",
    "    raise Exception(\"JSON value doesn't have lastSpotted, startTime, or endTime\")\n",
    "    \n",
    "def from_fleming(jdata, color):\n",
    "    headers = DEFAULT_HEADERS\n",
    "    odata = []\n",
    "    past_locations = {}\n",
    "    for idx, d in enumerate(jdata):\n",
    "        thedate = getDate(d)\n",
    "        lat = d['coordinates']['lat']\n",
    "        lon = d['coordinates']['lon']\n",
    "        k = f\"{lat}_{lon}\"\n",
    "        locname = k\n",
    "        if past_locations.get(k) is not None:\n",
    "            locname = past_locations[k]\n",
    "        else:\n",
    "            past_locations[f\"{lat}_{lon}\"] = locname\n",
    "        rdata = [\n",
    "            idx,\n",
    "            d['targetId'],\n",
    "            locname,\n",
    "            datetime.strftime(thedate, '%m/%d/%Y'),\n",
    "            datetime.strftime(thedate, '%H:%M:%S'),\n",
    "            lat,\n",
    "            lon,\n",
    "            \"alpha\", # just one category\n",
    "            d['targetId'],\n",
    "            color\n",
    "            \n",
    "        ]\n",
    "        odata.append(rdata)\n",
    "\n",
    "    return headers, odata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     3,
     21
    ]
   },
   "outputs": [],
   "source": [
    "#export\n",
    "CONVERTER = from_fleming\n",
    "\n",
    "def write_sheet(sheet, hdrs, rows):\n",
    "    row = 0\n",
    "    col = 0\n",
    "\n",
    "    for hdr in hdrs:\n",
    "        sheet.write(row, col, hdr)\n",
    "        col += 1\n",
    "\n",
    "    row = 1\n",
    "    col = 0\n",
    "\n",
    "    for rdata in rows:\n",
    "        col = 0\n",
    "        for cell in rdata:\n",
    "            sheet.write(row, col, cell)\n",
    "            col += 1\n",
    "        row += 1\n",
    "    \n",
    "def write_xlsx_from_json(inp:str,\n",
    "                 outp:str=\"out.xlsx\",\n",
    "                 color:str=\"red\",\n",
    "                 tabname:str=\"export_events\"):\n",
    "    workbook = xlsxwriter.Workbook(outp)\n",
    "    worksheet = workbook.add_worksheet(tabname)\n",
    "\n",
    "    with open(inp, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    conv_data = CONVERTER(data, color)\n",
    "    headers = conv_data[0]\n",
    "    row_data = conv_data[1]\n",
    "\n",
    "    write_sheet(worksheet, headers, row_data)\n",
    "    \n",
    "    workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to generate .xlsx and configs files\n",
    "Store the names of files processed in `created_sheets` for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     1,
     19
    ]
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def random_distinct_colors(n):\n",
    "    import random\n",
    "    ret = []\n",
    "    r = int(random.random() * 256)\n",
    "    g = int(random.random() * 256)\n",
    "    b = int(random.random() * 256)\n",
    "    step = 256 / n\n",
    "    for i in range(n):\n",
    "        r += step\n",
    "        g += step\n",
    "        b += step\n",
    "        r = int(r) % 256\n",
    "        g = int(g) % 256\n",
    "        b = int(b) % 256\n",
    "        ret.append(f\"rgb({r},{g},{b}\") \n",
    "    return ret\n",
    "\n",
    "def distinct_colors(n):\n",
    "    return COLS[:n]\n",
    "\n",
    "def derive_latlon(sheets, prefix):\n",
    "    import pandas as pd\n",
    "    # for the time being, just pick first\n",
    "    sheet =  pd.read_excel(output_xlsx / f\"{prefix}_{sheets[0]}.xlsx\", sheet_name='export_events')\n",
    "    for idx, row in sheet[['latitude', 'longitude']].iterrows():\n",
    "        return f\"[{row.latitude}, {row.longitude}]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     1,
     4,
     8,
     10
    ]
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def flatmap(f, items):\n",
    "    return chain.from_iterable(map(f, items))\n",
    "\n",
    "def get_files(country=None, with_indices=None, head=10) -> List:\n",
    "    \"\"\"\n",
    "    Get files with optional heuristic. Default to just picking the first 10\n",
    "    \"\"\"\n",
    "    if country is None:\n",
    "        files = list(flatmap(lambda x: [t for t in x.glob(\"**/*\") if t.is_file()], countries))\n",
    "    else: \n",
    "        if country == 'bhr':\n",
    "            w_folder = countries[0]\n",
    "        elif country == 'rwa1':\n",
    "            w_folder = countries[1]\n",
    "        elif country == 'is1':\n",
    "            w_folder = countries[2]\n",
    "        elif country == 'rwa2':\n",
    "            w_folder = countries[3]\n",
    "        elif country == 'sau':\n",
    "            w_folder = countries[4]\n",
    "\n",
    "        files = [t for t in w_folder.glob(\"**/*\") if t.is_file()]\n",
    "    \n",
    "    actual_files = []\n",
    "    if with_indices is not None:\n",
    "        idxs = with_indices(list(files))\n",
    "        for idx in idxs:\n",
    "            actual_files.append(files[idx])\n",
    "            \n",
    "    else:\n",
    "        # if `with_indices` not defined, take according to `head`\n",
    "        w_start = 0\n",
    "        w_end = head\n",
    "        \n",
    "        if head is not None:\n",
    "            for idx, x in enumerate(files):\n",
    "                if idx < w_start: continue\n",
    "                if idx >= w_end: break\n",
    "                actual_files.append(x)\n",
    "        else:\n",
    "            actual_files = files\n",
    "        \n",
    "    return actual_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def rewrite_xlsx_data(batch_prefix: str, limit_country=None, extract_targets=None) -> List:\n",
    "    \"\"\"\n",
    "    Rewrite the XLSX data in datasheet-server/data.\n",
    "    Returns a list of the sheets that are created, so that they can be threaded with \n",
    "    config creation.\n",
    "    \"\"\"\n",
    "    created_sheets = []\n",
    "    w_files = get_files(country=limit_country, with_indices=extract_targets)\n",
    "    colors = distinct_colors(len(w_files))\n",
    "    for idx, f in enumerate(w_files):\n",
    "        # create a f\"{f.name}.xlsx\" in output using main()\n",
    "        write_xlsx_from_json(f, output_xlsx/f\"{batch_prefix}_{f.stem}.xlsx\", colors[idx])\n",
    "        created_sheets.append(f.stem)\n",
    "\n",
    "    # make a metadata sheet for categories and filters\n",
    "    workbook = xlsxwriter.Workbook(output_xlsx/\"metadata.xlsx\")\n",
    "    write_sheet(workbook.add_worksheet('export_categories'),\n",
    "                ['category', 'description'],\n",
    "                [['alpha', 'the only category...']])\n",
    "    write_sheet(workbook.add_worksheet('export_filters'),\n",
    "                ['None'],\n",
    "                [[x] for x in created_sheets])\n",
    "    workbook.close()\n",
    "    return created_sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     1,
     7
    ]
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def gen_templates(created_sheets, w_prefix):\n",
    "    \"\"\"\n",
    "    Generate templates from a list of `created_sheets`, and a `w_prefix` that distinguishes\n",
    "    this set of targets from others.\n",
    "    \"\"\"\n",
    "    # event_exts, category_ext, map_anchor\n",
    "    tm_template = Template(\"\"\"module.exports = {\n",
    "      title: 'example',\n",
    "      display_title: 'Target Trace',\n",
    "      SERVER_ROOT: 'http://localhost:4040',\n",
    "      EVENTS_EXT: [\n",
    "          $event_exts\n",
    "      ],\n",
    "      CATEGORIES_EXT: '$categories_ext',\n",
    "      SOURCES_EXT: '',\n",
    "      NARRATIVES_EXT: '',\n",
    "      FILTERS_EXT: '$filters_ext',\n",
    "      SITES_EXT: '',\n",
    "      DATE_FMT: 'MM/DD/YYYY',\n",
    "      TIME_FMT: 'hh:mm:ss',\n",
    "\n",
    "      store: {\n",
    "        app: {\n",
    "          map: {\n",
    "            anchor: $map_anchor,\n",
    "            maxZoom: 20,\n",
    "            minZoom: 3,\n",
    "            startZoom: 15\n",
    "          },\n",
    "          timeline: {\n",
    "            range: [\n",
    "              new Date('2020-03-01T00:00:00Z'),\n",
    "              new Date('2020-05-01T00:00:00.000Z')\n",
    "            ],\n",
    "            rangeLimits: [\n",
    "              new Date('2019-01-01T00:00:00.000Z'),\n",
    "              new Date('2020-07-01T00:00:00.000Z')\n",
    "            ],\n",
    "            dimensions: {}\n",
    "          }\n",
    "        },\n",
    "        features: {\n",
    "          USE_COVER: false,\n",
    "          USE_CATEGORIES: true,\n",
    "          USE_FILTERS: true,\n",
    "          USE_SITES: false,\n",
    "          USE_SOURCES: false,\n",
    "          USE_NARRATIVES: false,\n",
    "          USE_SEARCH: false,\n",
    "          FILTERS_AS_NARRATIVES: true\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\")\n",
    "\n",
    "    single_xlsx = Template(\"\"\"{ name: '$name', path: 'data/$name.xlsx', tabs: timemap.default }\"\"\")\n",
    "\n",
    "    dss_template = Template(\"\"\"import { timemap } from './lib'\n",
    "\n",
    "    export default {\n",
    "      gsheets: [],\n",
    "      xlsx: [\n",
    "          { name: 'metadata', path: 'data/metadata.xlsx', tabs: timemap.default },\n",
    "          $xlsx_sheets\n",
    "      ]\n",
    "    }\n",
    "    \"\"\")\n",
    "\n",
    "    dss_config = dss_template.substitute(\n",
    "        xlsx_sheets=',\\n'.join([single_xlsx.substitute(name=f\"{w_prefix}_{s}\") for s in created_sheets])\n",
    "    )\n",
    "\n",
    "    tm_config = tm_template.substitute(\n",
    "        event_exts=\", \".join([f\"'/api/{w_prefix}_{x}/export_events/deeprows'\" for x in created_sheets]),\n",
    "        categories_ext=\"/api/metadata/export_categories/rows\",\n",
    "        filters_ext=\"/api/metadata/export_filters/tree\",\n",
    "        map_anchor=derive_latlon(created_sheets, w_prefix)\n",
    "    )\n",
    "\n",
    "    with (output/'timemap'/'config.js').open('w', encoding='utf-8') as f:\n",
    "        f.write(tm_config)\n",
    "    print(\"tm_config updated.\")\n",
    "\n",
    "    with (output/'datasheet-server'/'src'/'config.js').open('w', encoding='utf-8') as f:\n",
    "        f.write(dss_config)\n",
    "    print(\"dss_config updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     4,
     10
    ]
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "from convert_timemap.core import get_files\n",
    "\n",
    "def by_size(data):\n",
    "    data.sort(key=os.path.getsize, reverse=True)\n",
    "    w_start = 0 if len(data) < 10 else int(len(data) / 2)\n",
    "    w_end = 10 if len(data) < 10 else int(len(data) / 2) + 40\n",
    "    return range(w_start, w_end)\n",
    "\n",
    "def matching(ids):\n",
    "    def fn(data):\n",
    "        idxs = []\n",
    "        for idx, d in enumerate(data):\n",
    "            if d.stem in ids:\n",
    "                idxs.append(idx)\n",
    "        return idxs\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow to generate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tm_config updated.\n",
      "dss_config updated.\n"
     ]
    }
   ],
   "source": [
    "prefix = 'bhr'\n",
    "sheets = rewrite_xlsx_data(prefix, limit_country=prefix)\n",
    "gen_templates(sheets, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targets who travel in the West Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tm_config updated.\n",
      "dss_config updated.\n"
     ]
    }
   ],
   "source": [
    "prefix = 'westbankptrs'\n",
    "sheets = rewrite_xlsx_data(prefix, extract_targets=matching([\n",
    "    \"07ff82f3-dc83-4c6d-96dd-2e7b364b2b05\",\n",
    "    \"bc3558b5-c931-4359-956c-8b4403ded9cd\",\n",
    "    \"c8a85085-8c39-4908-b189-820df8c17055\",\n",
    "    \"92e9b5d9-75d1-429e-8d08-8d4d35600493\",\n",
    "    \"1219f151-93a4-465d-b59b-1d1000f33591\",\n",
    "    \"05e802f7-d2c5-445a-9e7b-351bc954cc84\"\n",
    "]))\n",
    "gen_templates(sheets, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targets who have locations logged in the ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tm_config updated.\n",
      "dss_config updated.\n"
     ]
    }
   ],
   "source": [
    "prefix = 'floatingsea'\n",
    "sheets = rewrite_xlsx_data(prefix, extract_targets=matching([\n",
    "    '761f5834-da25-43fa-8c38-6bc028184552',\n",
    "    '5d92105d-37b1-4a41-9eed-bce401e0446b',\n",
    "    '8caff79c-b876-439f-9844-321ae48c30ab',\n",
    "    'E643a715-ee9c-4c42-8863-96944adbba85'\n",
    "]))\n",
    "gen_templates(sheets, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample of targets in Dubai Creek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tm_config updated.\n",
      "dss_config updated.\n"
     ]
    }
   ],
   "source": [
    "prefix = 'dubaicreek'\n",
    "sheets = rewrite_xlsx_data(prefix, extract_targets=matching([\n",
    "    \"babf9d74-78d7-4d58-9f5e-effff79cf74f\",\n",
    "    \"b2cd6fd0-1804-4e4f-b9de-57d5d1b8f1a5\",\n",
    "    \"fca3217e-7dfb-4513-9880-b35a1a8f81cb\",\n",
    "    \"e7a75305-4017-43bd-adc1-b42d23ce6a48\",\n",
    "    \"d6e621f9-0a9c-43b7-8952-d2c150c8b156\",\n",
    "    \"c74ad488-9ff9-4d80-8cd8-f9ef4b24b6e6\",\n",
    "    \"5361cf54-b7f9-445f-9345-dcf3d2c597da\",\n",
    "    \"baf33fc2-87b9-4ee4-94ba-33606447f35d\",\n",
    "    \"5764d8ff-a8dc-4001-aaf2-1582f4e9ac80\",\n",
    "    \"d9e68c50-bae1-4aac-8d06-d9201752a64f\",\n",
    "    \"4dc21c45-e246-4108-bc47-756bcadbf243\"\n",
    "]))\n",
    "gen_templates(sheets, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unreasonable speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tm_config updated.\n",
      "dss_config updated.\n"
     ]
    }
   ],
   "source": [
    "prefix = 'unreasonablespeed'\n",
    "sheets = rewrite_xlsx_data(prefix, extract_targets=matching([\n",
    "    \"bc3558b5-c931-4359-956c-8b4403ded9cd\",\n",
    "    \"05e802f7-d2c5-445a-9e7b-351bc954cc84\",\n",
    "    \"b83344f3-303f-4e31-a909-c53ea8b01c4b\"\n",
    "]))\n",
    "gen_templates(sheets, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_statistics.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
